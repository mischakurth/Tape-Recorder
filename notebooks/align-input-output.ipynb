{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Dynamische Audio-Ausrichtung für Chunks (Batch-Verarbeitung)\n",
    "\n",
    "Dieses Notebook richtet ganze Ordner von sauberen Audio-Chunks (`clean`) dynamisch an entsprechende Tape-Output-Chunks (`tape`) aus. Es ist für die Batch-Verarbeitung optimiert.\n",
    "\n",
    "**Ziel:** Den lokalen Zeitversatz (Lag), der durch Tape-Aufnahmen entsteht, für kurze Audio-Chunks zu korrigieren.\n",
    "\n",
    "**Besonderheiten:**\n",
    "- **Hohe Sample Rate (96kHz):** Das Skript arbeitet nativ mit 96kHz-Audiodaten.\n",
    "- **Optimierte Lag-Berechnung:** Für die rechenintensive Kreuzkorrelation wird das Audio temporär auf eine niedrigere Sample Rate heruntergerechnet (`SR_CALC`), um die Performance zu steigern.\n",
    "- **Skalierung:** Die berechneten Lag-Werte werden präzise auf die ursprüngliche 96kHz-Zeitbasis zurückskaliert, bevor das finale Time-Warping auf die hochauflösenden Daten angewendet wird.\n",
    "- **Batch-Verarbeitung:** Das Skript durchsucht automatisch Input-Verzeichnisse, findet entsprechende Paare von Clean- und Tape-Chunks und verarbeitet sie nacheinander.\n",
    "- **Validierung:** Für jeden Chunk wird der verbleibende Versatz nach der Korrektur berechnet und ausgegeben, um den Erfolg der Ausrichtung zu überprüfen.\n"
   ],
   "id": "e3c3f302e27bf0d7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Import und Konfiguration",
   "id": "f8c1236f7f7c1de2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import scipy.signal\n",
    "from scipy.interpolate import interp1d\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from typing import Tuple, List\n",
    "from pathlib import Path\n",
    "import os\n"
   ],
   "id": "416074f3c7b3723c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Globale Parameter\n",
    "- **SR_ORIGINAL:** Die native Sample Rate der Quelldateien (z.B. 96000 Hz).\n",
    "- **SR_CALC:** Eine niedrigere Sample Rate (z.B. 16000 Hz) für die performante Berechnung des Lags.\n",
    "- **WINDOW_SEC / HOP_SEC:** Parameter für die fensterbasierte Analyse.\n",
    "- **MIN_CHUNK_DURATION_SEC:** Schwellenwert, unter dem Chunks als zu kurz für eine Analyse angesehen und übersprungen werden."
   ],
   "id": "a3c310b3fd603eae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# --- Globale Konfiguration ---\n",
    "SR_ORIGINAL = 96000  # Native Sample Rate der Audio-Dateien\n",
    "SR_CALC = 16000      # Niedrigere Sample Rate für die schnelle Lag-Berechnung\n",
    "\n",
    "WINDOW_SEC = 0.5     # Fenstergröße für die Analyse in Sekunden\n",
    "HOP_SEC = 0.25       # Schrittweite (Overlap) für die Analyse in Sekunden\n",
    "\n",
    "# Mindestlänge eines Chunks in Sekunden, um verarbeitet zu werden. Muss > WINDOW_SEC sein.\n",
    "MIN_CHUNK_DURATION_SEC = 0.6\n"
   ],
   "id": "5dd4c0b097f6aff0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Pfad-Konfiguration\n",
    "Das Skript geht von einer parallelen Ordnerstruktur aus:\n",
    "- `.../data/input/SET_NAME/CHUNK_NAME.wav` (Originale)\n",
    "- `.../data/output/SET_NAME_tape/CHUNK_NAME.wav` (Tape-Versionen)\n",
    "- `.../data/output/SET_NAME_aligned/CHUNK_NAME.wav` (Ergebnisdateien)"
   ],
   "id": "f75cea32644a6e7b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# --- Pfad-Konfiguration ---\n",
    "BASE_INPUT_DIR = Path(\"/Users/mischakurth/Documents/GitHub/mischakurth/xmas-hackathon-2025-bandsalat/data/audio/datasets/dataset-alfred/tape-input\")\n",
    "BASE_TAPE_DIR = Path(\"/Users/mischakurth/Documents/GitHub/mischakurth/xmas-hackathon-2025-bandsalat/data/audio/datasets/dataset-alfred/tape-output-recordings\")\n",
    "BASE_OUTPUT_DIR = Path(\"/Users/mischakurth/Documents/GitHub/mischakurth/xmas-hackathon-2025-bandsalat/data/audio/datasets/dataset-alfred/tape-input-warped\")\n"
   ],
   "id": "dd16db64ed1efe4c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Hilfsfunktionen",
   "id": "fcef62d9568c4ae2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### `compute_local_lags_resampled`\n",
    "Diese Funktion ist das Herzstück der Lag-Analyse. Sie nimmt die hochauflösenden Signale, resampelt sie auf `SR_CALC`, führt die fensterbasierte Kreuzkorrelation durch und skaliert die Ergebnisse (Zeitpunkte und Lag-Werte) wieder auf die `SR_ORIGINAL` hoch. Das spart erheblich Rechenzeit."
   ],
   "id": "7ec99b3e001b6799"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def compute_local_lags_resampled(\n",
    "    x_clean_orig: np.ndarray,\n",
    "    x_tape_orig: np.ndarray,\n",
    "    sr_orig: int,\n",
    "    sr_calc: int,\n",
    "    win_size_sec: float,\n",
    "    hop_size_sec: float\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Berechnet den lokalen Versatz bei einer niedrigeren Sample Rate, um die Performance zu verbessern.\n",
    "    \"\"\"\n",
    "    # 1. Resample für die Berechnung\n",
    "    resample_ratio = sr_calc / sr_orig\n",
    "    x_clean_calc = librosa.resample(y=x_clean_orig, orig_sr=sr_orig, target_sr=sr_calc)\n",
    "    x_tape_calc = librosa.resample(y=x_tape_orig, orig_sr=sr_orig, target_sr=sr_calc)\n",
    "\n",
    "    # 2. Fenster-Parameter für die Berechnungs-Sample-Rate bestimmen\n",
    "    win_size_calc = int(win_size_sec * sr_calc)\n",
    "    hop_size_calc = int(hop_size_sec * sr_calc)\n",
    "\n",
    "    lags_calc = []\n",
    "    time_points_calc = []\n",
    "    max_lag_search_calc = int(2000 * resample_ratio) # Skaliere auch den Suchbereich\n",
    "\n",
    "    num_windows = int((len(x_tape_calc) - win_size_calc) / hop_size_calc)\n",
    "    if num_windows == 0:\n",
    "        return np.array([]), np.array([])\n",
    "\n",
    "    for i in range(num_windows):\n",
    "        start = i * hop_size_calc\n",
    "        end = start + win_size_calc\n",
    "        seg_clean = x_clean_calc[start:end]\n",
    "        seg_tape = x_tape_calc[start:end]\n",
    "\n",
    "        corr = scipy.signal.correlate(seg_tape, seg_clean, mode='same', method='fft')\n",
    "\n",
    "        mid_point = len(corr) // 2\n",
    "        search_start = max(0, mid_point - max_lag_search_calc)\n",
    "        search_end = min(len(corr), mid_point + max_lag_search_calc)\n",
    "\n",
    "        search_area = corr[search_start:search_end]\n",
    "        if len(search_area) == 0: continue\n",
    "\n",
    "        peak_idx_relative = np.argmax(search_area)\n",
    "        current_lag = (search_start + peak_idx_relative) - mid_point\n",
    "\n",
    "        lags_calc.append(current_lag)\n",
    "        time_points_calc.append(start + win_size_calc // 2)\n",
    "\n",
    "    # 3. Zeitpunkte und Lags zurück auf die originale Sample Rate skalieren\n",
    "    scale_factor = sr_orig / sr_calc\n",
    "    time_points_orig = np.array(time_points_calc) * scale_factor\n",
    "    lags_orig = np.array(lags_calc) * scale_factor\n",
    "\n",
    "    return time_points_orig, lags_orig\n"
   ],
   "id": "165c51f80d387d77"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### `apply_warping_full_res`\n",
    "Diese Funktion nimmt die hochskalierten Lag-Werte und wendet sie auf das *originale*, hochauflösende Signal an. Sie glättet zunächst die Lag-Kurve, interpoliert sie auf die volle Sample-Anzahl und führt dann das Time-Warping mittels kubischer Interpolation durch."
   ],
   "id": "6f781f663090996"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def apply_warping_full_res(\n",
    "    x_clean: np.ndarray,\n",
    "    lags: np.ndarray,\n",
    "    lag_times: np.ndarray\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Wendet die skalierten Lags auf das hochauflösende Originalsignal an.\n",
    "    \"\"\"\n",
    "    total_length = len(x_clean)\n",
    "\n",
    "    # Glätte die Lags, um Ausreißer zu entfernen.\n",
    "    # Der Median-Filter ist robust gegen einzelne falsche Messungen.\n",
    "    # Die Kernel-Größe muss ungerade sein.\n",
    "    kernel_size = min(15, len(lags) - (1 if len(lags) % 2 == 0 else 0))\n",
    "    if kernel_size < 1: kernel_size = 1\n",
    "    lags_smooth = scipy.signal.medfilt(lags, kernel_size=kernel_size)\n",
    "\n",
    "    # Interpoliere die geglätteten Lags auf die volle Länge des Signals.\n",
    "    lag_interpolator = interp1d(lag_times, lags_smooth, kind='linear', fill_value=\"extrapolate\")\n",
    "    all_sample_indices = np.arange(total_length)\n",
    "    smooth_lag_map = lag_interpolator(all_sample_indices)\n",
    "\n",
    "    # Erstelle eine Interpolationsfunktion für das saubere Signal, um es an nicht-ganzzahligen\n",
    "    # Positionen abtasten zu können (Time-Warping).\n",
    "    clean_interpolator = interp1d(np.arange(len(x_clean)), x_clean, kind='cubic', fill_value=0.0, bounds_error=False)\n",
    "\n",
    "    # Berechne die neuen, verschobenen Sample-Positionen.\n",
    "    warped_indices = all_sample_indices - smooth_lag_map\n",
    "\n",
    "    # Erzeuge das ausgerichtete Signal.\n",
    "    x_clean_aligned = clean_interpolator(warped_indices)\n",
    "\n",
    "    return x_clean_aligned\n"
   ],
   "id": "119847bb8bff0685"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### `verify_alignment`\n",
    "Eine einfache, aber effektive Metrik, um den Erfolg der Ausrichtung zu messen. Sie berechnet die Kreuzkorrelation zwischen dem Zielsignal (Tape) und dem neuen, ausgerichteten Signal. Der Peak der Korrelation sollte idealerweise bei einem Offset von 0 Samples liegen."
   ],
   "id": "4f6b73ac8b7f59a3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def verify_alignment(x_tape: np.ndarray, x_aligned: np.ndarray) -> int:\n",
    "    \"\"\"\n",
    "    Berechnet den verbleibenden Offset zwischen zwei Signalen via Kreuzkorrelation.\n",
    "    Ein perfektes Ergebnis ist 0.\n",
    "    \"\"\"\n",
    "    correlation = scipy.signal.correlate(x_tape, x_aligned, mode='same', method='fft')\n",
    "    offset = np.argmax(correlation) - len(correlation) // 2\n",
    "    return offset\n"
   ],
   "id": "a13431e7a9869e3c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Haupt-Workflow: Batch-Verarbeitung",
   "id": "75ab16d08b705b4d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### `find_chunk_pairs`\n",
    "Diese Funktion durchsucht die Verzeichnisstruktur und erstellt eine Liste von zu verarbeitenden Paaren aus Clean- und Tape-Chunks."
   ],
   "id": "ba0199e74339ef76"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def find_chunk_pairs(input_dir: Path, tape_dir: Path) -> List[Tuple[Path, Path]]:\n",
    "    \"\"\"Findet Paare von (clean_chunk, tape_chunk) basierend auf dem Dateinamen.\"\"\"\n",
    "    pairs = []\n",
    "    print(f\"Suche nach Chunks in: {input_dir}\")\n",
    "    for clean_path in sorted(input_dir.rglob('*.wav')):\n",
    "        relative_path = clean_path.relative_to(input_dir)\n",
    "        tape_path = tape_dir / relative_path\n",
    "        if tape_path.exists():\n",
    "            pairs.append((clean_path, tape_path))\n",
    "    print(f\"Gefunden: {len(pairs)} Paare.\")\n",
    "    return pairs\n"
   ],
   "id": "91528da10b63c94"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### `process_chunk`\n",
    "Diese Funktion kapselt die gesamte Logik für ein einzelnes Chunk-Paar: Laden, Validieren, Lag-Berechnung, Warping, Verifizierung und Speichern. Sie gibt detaillierte Status- und Fehlermeldungen aus."
   ],
   "id": "fe8b570639d36bdd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def process_chunk(clean_path: Path, tape_path: Path, output_path: Path):\n",
    "    \"\"\"Führt den kompletten Ausrichtungsprozess für ein einzelnes Chunk-Paar durch.\"\"\"\n",
    "    try:\n",
    "        # 1. Laden und Sample Rate prüfen\n",
    "        y_clean, sr_c = librosa.load(clean_path, sr=None, mono=True)\n",
    "        y_tape, sr_t = librosa.load(tape_path, sr=None, mono=True)\n",
    "\n",
    "        if sr_c != SR_ORIGINAL or sr_t != SR_ORIGINAL:\n",
    "            print(f\"  SKIPPED: {clean_path.name} (Falsche SR. Erwartet: {SR_ORIGINAL}, gefunden: {sr_c}/{sr_t})\")\n",
    "            return\n",
    "\n",
    "        # 2. Chunk-Länge validieren\n",
    "        duration_sec = len(y_clean) / SR_ORIGINAL\n",
    "        if duration_sec < MIN_CHUNK_DURATION_SEC:\n",
    "            print(f\"  SKIPPED: {clean_path.name} (Zu kurz: {duration_sec:.2f}s < {MIN_CHUNK_DURATION_SEC}s)\")\n",
    "            return\n",
    "\n",
    "        min_len = min(len(y_clean), len(y_tape))\n",
    "        y_clean, y_tape = y_clean[:min_len], y_tape[:min_len]\n",
    "\n",
    "        # 3. Lokalen Versatz berechnen\n",
    "        times, raw_lags = compute_local_lags_resampled(y_clean, y_tape, SR_ORIGINAL, SR_CALC, WINDOW_SEC, HOP_SEC)\n",
    "\n",
    "        if len(times) == 0:\n",
    "            print(f\"  SKIPPED: {clean_path.name} (Keine Lags berechenbar, evtl. zu wenig Analysefenster)\")\n",
    "            return\n",
    "\n",
    "        # 4. Warping anwenden\n",
    "        y_clean_aligned = apply_warping_full_res(y_clean, raw_lags, times)\n",
    "\n",
    "        # 5. Ergebnis verifizieren\n",
    "        final_offset = verify_alignment(y_tape, y_clean_aligned)\n",
    "        print(f\"  SUCCESS: {clean_path.name} -> Verbleibender Versatz: {final_offset} Samples.\")\n",
    "\n",
    "        # 6. Speichern\n",
    "        output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        sf.write(output_path, y_clean_aligned, SR_ORIGINAL)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  ERROR:   {clean_path.name} ({e})\")\n"
   ],
   "id": "9d31c58649158327"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Ausführung der Batch-Verarbeitung\n",
    "Der folgende Code-Block startet den Prozess. Er iteriert durch alle Unterordner im `BASE_INPUT_DIR`, findet die entsprechenden Tape-Ordner, sucht nach Chunk-Paaren und startet die Verarbeitung für jedes Paar. Bereits existierende Output-Dateien werden übersprungen."
   ],
   "id": "6019519701a8fae8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# --- Start der Batch-Verarbeitung ---\n",
    "if __name__ == '__main__':\n",
    "    input_sets = [d for d in BASE_INPUT_DIR.iterdir() if d.is_dir()]\n",
    "\n",
    "    for input_set_dir in input_sets:\n",
    "        set_name = input_set_dir.name\n",
    "        print(f\"\\n--- Verarbeite Set: {set_name} ---\")\n",
    "\n",
    "        tape_set_dir = BASE_TAPE_DIR / f\"{set_name}_tape\"\n",
    "        output_set_dir = BASE_OUTPUT_DIR / f\"{set_name}_aligned\"\n",
    "\n",
    "        if not tape_set_dir.exists():\n",
    "            print(f\"WARNUNG: Tape-Verzeichnis {tape_set_dir} nicht gefunden. Überspringe Set.\")\n",
    "            continue\n",
    "\n",
    "        chunk_pairs = find_chunk_pairs(input_set_dir, tape_set_dir)\n",
    "        processed_count = 0\n",
    "\n",
    "        for i, (clean_path, tape_path) in enumerate(chunk_pairs):\n",
    "            relative_path = clean_path.relative_to(input_set_dir)\n",
    "            output_path = output_set_dir / relative_path\n",
    "\n",
    "            if output_path.exists():\n",
    "                continue\n",
    "\n",
    "            if processed_count > 0 and processed_count % 50 == 0:\n",
    "                print(f\"  ... {processed_count}/{len(chunk_pairs)} Chunks verarbeitet ...\")\n",
    "\n",
    "            process_chunk(clean_path, tape_path, output_path)\n",
    "            processed_count += 1\n",
    "\n",
    "        print(f\"--- Set {set_name} abgeschlossen. {processed_count} neue Chunks verarbeitet. ---\")\n",
    "\n",
    "    print(\"\\n--- Batch-Verarbeitung vollständig abgeschlossen. ---\")\n"
   ],
   "id": "355d3fec74e8a27d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
