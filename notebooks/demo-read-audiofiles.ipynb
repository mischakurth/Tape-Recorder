{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Read Audio Files\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "- Load and inspect WAV audio files using librosa and pydub\n",
    "- Display waveforms and spectrograms\n",
    "- Normalize audio to a target peak level (dBFS)\n",
    "- Play audio inline in Jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports-header",
   "metadata": {},
   "source": [
    "## 1. Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add project root to path for imports\n",
    "sys.path.insert(0, os.path.dirname(os.path.abspath(\".\")))\n",
    "\n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from pydub import AudioSegment\n",
    "\n",
    "from src.utils import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "cfg = Config()\n",
    "cfg.print_paths()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-header",
   "metadata": {},
   "source": [
    "## 2. List Available Audio Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "list-samples",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get samples directory from config\n",
    "SAMPLES_DIR = cfg.get_audio_assets_dir() / \"samples\"\n",
    "\n",
    "print(f\"Samples directory: {SAMPLES_DIR}\")\n",
    "print(\"\\nAvailable audio files:\")\n",
    "\n",
    "wav_files = [f for f in os.listdir(SAMPLES_DIR) if f.endswith('.wav')]\n",
    "wav_files.sort()\n",
    "for f in wav_files:\n",
    "    print(f\"  {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-single-header",
   "metadata": {},
   "source": [
    "## 3. Load and Inspect a Single Audio File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-audio",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select an audio file to analyze\n",
    "file = SAMPLES_DIR / wav_files[0]  # Change index to select different file\n",
    "\n",
    "if not os.path.exists(file):\n",
    "    print(f'ERROR: File \"{file}\" was NOT found.')\n",
    "else:\n",
    "    # Load audio with librosa\n",
    "    audio_sample, sr = librosa.load(file)\n",
    "    samples = len(audio_sample)\n",
    "    \n",
    "    print(f\"File       : {os.path.basename(file)}\")\n",
    "    print(f\"Sample rate: {sr} Hz\")\n",
    "    print(f\"Samples    : {samples}\")\n",
    "    print(f\"Duration   : {1000 * samples / sr:.0f} ms\")\n",
    "    print()\n",
    "    \n",
    "    # Play audio inline\n",
    "    ipd.display(ipd.Audio(str(file)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "waveform-header",
   "metadata": {},
   "source": [
    "## 4. Display Waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "waveform",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.waveshow(audio_sample, sr=sr, color=\"yellow\")\n",
    "plt.title(f\"Waveform: {os.path.basename(file)}\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spectrogram-header",
   "metadata": {},
   "source": [
    "## 5. Display Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spectrogram",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Short-Time Fourier Transform\n",
    "X = librosa.stft(audio_sample)\n",
    "Xdb = librosa.amplitude_to_db(abs(X))\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title(f\"Spectrogram: {os.path.basename(file)}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "normalize-header",
   "metadata": {},
   "source": [
    "## 6. Audio Normalization (dBFS)\n",
    "\n",
    "Normalize audio to a target peak level using pydub. This is useful for:\n",
    "- Ensuring consistent volume across samples\n",
    "- Data augmentation (creating samples at different volume levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normalize",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximize_audio(audio_sample: AudioSegment, target_max_dBFS: float = -0.1) -> AudioSegment:\n",
    "    \"\"\"Normalize audio to a target peak level.\n",
    "    \n",
    "    Args:\n",
    "        audio_sample: PyDub AudioSegment to normalize\n",
    "        target_max_dBFS: Target peak level in dBFS (0 = maximum, negative = quieter)\n",
    "    \n",
    "    Returns:\n",
    "        Normalized AudioSegment\n",
    "    \"\"\"\n",
    "    gain = -audio_sample.max_dBFS + target_max_dBFS\n",
    "    return audio_sample.apply_gain(gain)\n",
    "\n",
    "\n",
    "# Load with pydub for dBFS analysis\n",
    "audio_pydub = AudioSegment.from_file(str(file))\n",
    "print(f\"Original peak level: {audio_pydub.max_dBFS:.2f} dBFS\")\n",
    "\n",
    "# Normalize to -0.1 dBFS (near maximum without clipping)\n",
    "audio_normalized = maximize_audio(audio_pydub, target_max_dBFS=-0.1)\n",
    "print(f\"Normalized peak level: {audio_normalized.max_dBFS:.2f} dBFS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compare-header",
   "metadata": {},
   "source": [
    "## 7. Compare Original vs Normalized Waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compare",
   "metadata": {},
   "outputs": [],
   "source": "# Export normalized audio to temporary file for visualization\ntemp_dir = cfg.get_playground_dir() / \"demo-read-audiofiles\"\nos.makedirs(temp_dir, exist_ok=True)\ntemp_file = temp_dir / \"temp_normalized.wav\"\naudio_normalized.export(str(temp_file), format=\"wav\")\n\n# Load normalized audio for plotting\naudio_normalized_np, sr_norm = librosa.load(str(temp_file))\n\n# Plot comparison\nfig, axes = plt.subplots(2, 1, figsize=(14, 8))\n\naxes[0].set_title(f\"Original (peak: {audio_pydub.max_dBFS:.2f} dBFS)\")\nlibrosa.display.waveshow(audio_sample, sr=sr, ax=axes[0], color=\"yellow\", alpha=0.7)\naxes[0].set_ylabel(\"Amplitude\")\n\naxes[1].set_title(f\"Normalized (peak: {audio_normalized.max_dBFS:.2f} dBFS)\")\nlibrosa.display.waveshow(audio_normalized_np, sr=sr_norm, ax=axes[1], color=\"cyan\", alpha=0.7)\naxes[1].set_ylabel(\"Amplitude\")\naxes[1].set_xlabel(\"Time (s)\")\n\nplt.tight_layout()\nplt.show()\n\n# Play normalized audio\nprint(\"\\nNormalized audio:\")\nipd.display(ipd.Audio(str(temp_file)))\n\n# Clean up\nos.remove(temp_file)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}